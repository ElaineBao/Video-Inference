# 视频分类inference API （v1）
## 0. 技术方案
输入：input video          
-> 截帧（ffmpeg）    
-> 特征提取（SENet）    
-> 多帧特征融合（NetVLAD）         
-> 多帧分类（FC)     
-> 后处理       
输出：视频的多个分类标签，及其分别所处的开始时间和结束时间

## 1. 截帧
采用ffmpeg对视频进行处理，包括：    
（1）视频信息提取：帧率，帧大小，视频时长等；     
（2）截帧：包括逐帧截取，和每n帧截取1帧两种截帧方式；    
（3）形成帧组： 为便于后面进行多帧特征融合的方便，在此处将多帧组合进行输出。

## 2. 特征提取
采用SENet对帧进行特征提取，输入不定长的帧，输出不定长的SENet特征。    
目前提特征所采用的框架是caffe，代码已经从叶博那边要到了，需要重新建个镜像调试好专门用于提特征。

## 3. 多帧特征融合
采用NetVLAD将多帧特征进行重新编码，输入多帧特征，输出一个新的特征表示。实际中，3和4两个步骤是合在一起训练的，因此inference也在一起。

## 4. 多帧分类
将NetVLAD输出的特征输入到FC中进行视频分类。实际中3和4两个步骤是合在一起的。

## 5. 后处理
将分类结果做一个整合，输出视频的多个分类标签，及其分别所处的开始时间和结束时间。
